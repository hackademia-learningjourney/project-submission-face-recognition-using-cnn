{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (14, 224, 224, 3)\n",
      "y_train shape: (14, 2)\n",
      "x_test shape: (4, 224, 224, 3)\n",
      "y_test shape: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = np.load('image_dataset.npz')\n",
    "\n",
    "\n",
    "images = data['data']\n",
    "labels = data['labels']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train, dtype='float32') / 255\n",
    "x_test = np.array(x_test, dtype='float32') / 255\n",
    "\n",
    "\n",
    "num_classes = np.max(labels) + 1\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid= train_test_split(\n",
    "    x_train, y_train, test_size=.05, random_state=1234,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.3636 - loss: 0.7641 - val_accuracy: 0.6667 - val_loss: 1.0982\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step - accuracy: 0.6364 - loss: 1.0840 - val_accuracy: 0.6667 - val_loss: 0.8263\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 0.6364 - loss: 0.7951 - val_accuracy: 0.6667 - val_loss: 0.6125\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664ms/step - accuracy: 0.6364 - loss: 0.5820 - val_accuracy: 1.0000 - val_loss: 0.6335\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step - accuracy: 1.0000 - loss: 0.6013 - val_accuracy: 0.6667 - val_loss: 0.6546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5814129710197449\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = np.load('image_dataset.npz')\n",
    "\n",
    "images = data['data']\n",
    "labels = data['labels']\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "x_train = np.array(x_train, dtype='float32') / 255\n",
    "x_test = np.array(x_test, dtype='float32') / 255\n",
    "\n",
    "\n",
    "num_classes = np.max(labels) + 1\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(x_train.shape[1:])),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "model.save('simple_cnn_model.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "input_shape = (224, 224, 1)  \n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),  \n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, target_size):\n",
    "    \n",
    "    img = cv2.resize(img, target_size)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)  \n",
    "    img = np.expand_dims(img, axis=-1)  \n",
    "    img = img.astype('float32') / 255  \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to capture the image.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step\n",
      "Face recognized as class: 1 with confidence: 0.52\n"
     ]
    }
   ],
   "source": [
    "\n",
    "captured_image = capture_image()\n",
    "\n",
    "target_size = (224, 224)  \n",
    "preprocessed_image = preprocess_image(captured_image, target_size)\n",
    "\n",
    "\n",
    "prediction = model.predict(preprocessed_image)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "confidence = np.max(prediction)  \n",
    "\n",
    "\n",
    "recognition_threshold = 0.5  \n",
    "if confidence > recognition_threshold:\n",
    "    print(f'Face recognized as class: {predicted_class[0]} with confidence: {confidence:.2f}')\n",
    "else:\n",
    "    print('Face not recognized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
